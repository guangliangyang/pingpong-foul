# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16jMmAeYmA1zJwRIQfs-2BXlr-HnfYe2I

# AUTOENCODER AND PSO FOR ABNORMAL DETECTION IN IoT

# **Project Workflow**

1. **Import Libraries**
    * Import necessary libraries like numpy, matplotlib, Pytorch.

2. **DATA Process**
    * loade the dataset using pandas and performed an initial exploration to understand its structure and identify any immediate issues
    * checke for and addressed any missing values in the dataset.
    * take sample of the dataset.
    * removed non-numeric and identifier columns that are not suitable for the autoencoder model, such as IP addresses.
3. **Define the threshold**
    * Define the threshold.
    * Define the abnormaly detection function.

4. **Implement Bachmark**
    * Set a random parameter for a autoencoder algorithm.
    * get results.
    
5. **Implement Autoencoder and PSO**
    * Algorithms Description
    * Parameters Analysis (Set the parameters planned to vary)
    * Conclusion(Analyze how changing parameters impacted the agents' performance)

5. **Conclusion**
    * Summarize the key findings and suggest potential improvements or future work

**1. Import Libraries**
"""


import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
from pyswarms.single.global_best import GlobalBestPSO
import matplotlib.pyplot as plt
from tqdm import tqdm
import torch.nn.functional as F
from sklearn.metrics import classification_report, confusion_matrix
from torchsummary import summary

np.random.seed(42)
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed(42)

"""**Check GPU Availibility**"""

print(f"CUDA is available: {torch.cuda.is_available()}")
print(f"Current device: {torch.cuda.current_device()}")
print(f"Device name: {torch.cuda.get_device_name(0)}")

"""**Define the device**"""

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

"""**LOAD DATA**

"""

file_path = 'NF-CSE-CIC-IDS2018-v2.csv'
meta_data= pd.read_csv(file_path)
meta_data

print(meta_data.shape)
print(meta_data.columns)
Attack_counts = meta_data['Attack'].value_counts()
print(Attack_counts)

print(meta_data.isnull().sum())
meta_data = meta_data.dropna()

#sample_size = int(len(meta_data) * 0.01)  # using 1% dataset
#data = meta_data.sample(n=sample_size, random_state=42)
data = meta_data

data.drop(columns=['Label','IPV4_SRC_ADDR', 'IPV4_DST_ADDR'],inplace = True)
data.rename(columns={"Attack":"label"}, inplace=True)

label_counts = data['label'].value_counts()
print(label_counts)

"""**Split DATA**"""

# Split data
X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['label']), data['label'], test_size=0.2, random_state=42)

# Normalize data
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

normal_data = X_train_scaled[y_train == 'Benign']
anomaly_data = X_train_scaled[y_train != 'Benign']

x_train, x_val = train_test_split(normal_data, test_size=0.2)
x_train = torch.from_numpy(x_train).float().to(device)
x_val = torch.from_numpy(x_val).float().to(device)

test_tensor=torch.tensor(X_test_scaled, dtype=torch.float32).to(device)
normal_tensor=torch.tensor(normal_data, dtype=torch.float32).to(device)

"""**Define the Threshold and Detection Anormalies Functions**"""

# @title
def calculate_threshold(model, data):
    """Calculate threshold based on reconstruction error of normal data"""
    model.eval()
    with torch.no_grad():
        normal_flag = model(data)
        mse = nn.MSELoss(reduction='none')(normal_flag, data)
        normal_flag_errors = mse.mean(dim=1).cpu().numpy()
        return np.percentile(normal_flag_errors, 95)

def detect_anomalies(model, data, threshold):
    """Detect anomalies using the trained model"""
    model.eval()
    with torch.no_grad():
        reconstructions = model(data)
        mse = nn.MSELoss(reduction='none')(reconstructions, data)
        reconstruction_errors = mse.mean(dim=1).cpu().numpy()
        return reconstruction_errors > threshold

"""**Setting Banchmark**"""

# @title
# Define Autoencoder model
class Autoencoder_base(nn.Module):
    def __init__(self, input_dim, encoding_dim):
        super(Autoencoder_base, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.Linear(16, 32),
            nn.ReLU(),
            nn.Linear(32, 64),
            nn.ReLU(),
            nn.Linear(64, input_dim),
            nn.Sigmoid()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

def train_eval( x_train, x_val, epochs, batch_size, input_dim):
    best_loss = float('inf')
    # Early stopping parameters
    patience = 5  # 连续5次没有改善就停止
    min_delta = 0.001  # 最小改善阈值
    patience_counter = 0

    model = Autoencoder_base(input_dim, 16).to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters())

    train_loader_b = DataLoader(TensorDataset(x_train, x_train), batch_size=batch_size, shuffle=True)
    val_loader_b = DataLoader(TensorDataset(x_val, x_val), batch_size=batch_size)
    best_model_state = None
    train_loss_baseline_all=[]
    val_loss_baseline_all=[]
    # Training loop
    for epoch in range(epochs):
        model.train()
        train_loss_b = 0
        num_batches = 0
        for batch in train_loader_b:
            batch = batch[0].to(device)  # Move batch to GPU
            optimizer.zero_grad()
            outputs = model(batch)
            loss = criterion(outputs, batch)
            loss.backward()
            optimizer.step()
            train_loss_b += loss.item()
            num_batches += 1
        train_loss_b /= num_batches
        train_loss_baseline_all.append(train_loss_b)

        # Validation
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for batch_x, _ in val_loader_b:
                outputs = model(batch_x)
                val_loss += criterion(outputs, batch_x).item()
        val_loss /= len(val_loader_b)
        val_loss_baseline_all.append(val_loss)

        # Early stopping check
        if val_loss < best_loss - min_delta:
            best_loss = val_loss
            patience_counter = 0
            best_model_state = model.state_dict().copy()  # 存储模型状态而不是保存到文件
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f'Early stopping triggered at epoch {epoch+1}')
                break

    model.load_state_dict(best_model_state)
    return model, train_loss_baseline_all, val_loss_baseline_all

epochs = 50
batch_size = 32
input_dim = normal_data.shape[1]
model_baseline, train_losses_baseline, val_losses_baseline = train_eval(x_train=x_train, x_val=x_val,
                                             epochs=epochs, batch_size=batch_size, input_dim=input_dim)
threshold_baseline = calculate_threshold(model_baseline, normal_tensor)

y_pred_baseline = detect_anomalies(model_baseline, test_tensor, threshold_baseline)
y_test_binary = (y_test != 'Benign').astype(int)
Accuracy_baseline = np.mean(y_pred_baseline == y_test_binary)

# Print results
print(f'Accuracy: {Accuracy_baseline}')
print(f'Threshold: {threshold_baseline}')
print(classification_report(y_test_binary, y_pred_baseline))
print(confusion_matrix(y_test_binary, y_pred_baseline))

plt.figure(figsize=(10, 6))
plt.plot(train_losses_baseline, label='Train Loss baseline')
plt.plot(val_losses_baseline, label='Validation Loss baseline')
plt.title('Loss vs. Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

"""**Define the Autoencoder**"""
