{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-31T08:39:24.114455Z",
     "start_time": "2024-10-31T08:34:01.584068Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Check GPU Availability\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load Data\n",
    "file_path = 'NF-CSE-CIC-IDS2018-v2.csv'\n",
    "meta_data = pd.read_csv(file_path)\n",
    "\n",
    "print(meta_data.shape)\n",
    "print(meta_data.columns)\n",
    "Attack_counts = meta_data['Attack'].value_counts()\n",
    "print(Attack_counts)\n",
    "\n",
    "print(meta_data.isnull().sum())\n",
    "meta_data = meta_data.dropna()\n",
    "\n",
    "data = meta_data\n",
    "data.drop(columns=['Label', 'IPV4_SRC_ADDR', 'IPV4_DST_ADDR'], inplace=True)\n",
    "data.rename(columns={\"Attack\": \"label\"}, inplace=True)\n",
    "\n",
    "label_counts = data['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(columns=['label']), data['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Normalize Data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "normal_data = X_train_scaled[y_train == 'Benign']\n",
    "anomaly_data = X_train_scaled[y_train != 'Benign']\n",
    "\n",
    "x_train, x_val = train_test_split(normal_data, test_size=0.2)\n",
    "x_train = torch.from_numpy(x_train).float().to(device)\n",
    "x_val = torch.from_numpy(x_val).float().to(device)\n",
    "\n",
    "test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "normal_tensor = torch.tensor(normal_data, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the Autoencoder model\n",
    "class Autoencoder_base(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(Autoencoder_base, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Model path for saving and loading\n",
    "model_path = 'autoencoder_baseline.pth'\n",
    "\n",
    "def train_eval(x_train, x_val, epochs, batch_size, input_dim):\n",
    "    # Check if model already exists\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Loading saved model...\")\n",
    "        model = Autoencoder_base(input_dim, 16).to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        return model, [], []\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    patience = 5\n",
    "    min_delta = 0.001\n",
    "    patience_counter = 0\n",
    "\n",
    "    model = Autoencoder_base(input_dim, 16).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_loader_b = DataLoader(TensorDataset(x_train, x_train), batch_size=batch_size, shuffle=True)\n",
    "    val_loader_b = DataLoader(TensorDataset(x_val, x_val), batch_size=batch_size)\n",
    "    best_model_state = None\n",
    "    train_loss_baseline_all = []\n",
    "    val_loss_baseline_all = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss_b = 0\n",
    "        num_batches = 0\n",
    "        for batch in train_loader_b:\n",
    "            batch = batch[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_b += loss.item()\n",
    "            num_batches += 1\n",
    "        train_loss_b /= num_batches\n",
    "        train_loss_baseline_all.append(train_loss_b)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, _ in val_loader_b:\n",
    "                outputs = model(batch_x)\n",
    "                val_loss += criterion(outputs, batch_x).item()\n",
    "        val_loss /= len(val_loader_b)\n",
    "        val_loss_baseline_all.append(val_loss)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_loss - min_delta:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "                break\n",
    "\n",
    "    # Save the best model state if training was conducted\n",
    "    model.load_state_dict(best_model_state)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(\"Model saved.\")\n",
    "\n",
    "    return model, train_loss_baseline_all, val_loss_baseline_all\n",
    "\n",
    "# Training or loading the model\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "input_dim = normal_data.shape[1]\n",
    "model_baseline, train_losses_baseline, val_losses_baseline = train_eval(\n",
    "    x_train=x_train, x_val=x_val, epochs=epochs, batch_size=batch_size, input_dim=input_dim\n",
    ")\n",
    "\n",
    "# Define threshold and detect anomalies\n",
    "def calculate_threshold(model, data, percentile):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        normal_flag = model(data)\n",
    "        mse = nn.MSELoss(reduction='none')(normal_flag, data)\n",
    "        normal_flag_errors = mse.mean(dim=1).cpu().numpy()\n",
    "        return np.percentile(normal_flag_errors, percentile)\n",
    "\n",
    "def detect_anomalies(model, data, threshold):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        reconstructions = model(data)\n",
    "        mse = nn.MSELoss(reduction='none')(reconstructions, data)\n",
    "        reconstruction_errors = mse.mean(dim=1).cpu().numpy()\n",
    "        return reconstruction_errors > threshold\n",
    "\n",
    "# Binary encoding of labels for evaluation\n",
    "y_test_binary = (y_test != 'Benign').astype(int)\n",
    "\n",
    "# Set a fixed threshold at the 95th percentile for evaluation\n",
    "starting_threshold_percentile = 94.5\n",
    "optimal_threshold = calculate_threshold(model_baseline, normal_tensor, starting_threshold_percentile)\n",
    "y_pred_optimized = detect_anomalies(model_baseline, test_tensor, optimal_threshold)\n",
    "\n",
    "# Evaluate the results with the fixed threshold\n",
    "accuracy_optimized = np.mean(y_pred_optimized == y_test_binary)\n",
    "f1_class_1 = f1_score(y_test_binary, y_pred_optimized, pos_label=1)\n",
    "\n",
    "# Print results\n",
    "print(f'Fixed Threshold Percentile: {starting_threshold_percentile}')\n",
    "print(f'Fixed Threshold Value: {optimal_threshold}')\n",
    "print(f'Optimized Accuracy: {accuracy_optimized}')\n",
    "print(f'Optimized F1 Score for class 1: {f1_class_1}')\n",
    "print(classification_report(y_test_binary, y_pred_optimized))\n",
    "print(confusion_matrix(y_test_binary, y_pred_optimized))\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses_baseline, label='Train Loss baseline')\n",
    "plt.plot(val_losses_baseline, label='Validation Loss baseline')\n",
    "plt.title('Loss vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Model saved to autoencoder.pth\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (axis=NoneType, out=NoneType, ), but expected one of:\n * ()\n * (Tensor other)\n * (int dim, bool keepdim = False)\n      didn't match because some of the keywords were incorrect: axis, out\n * (name dim, bool keepdim = False)\n      didn't match because some of the keywords were incorrect: axis, out\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 128\u001B[0m\n\u001B[0;32m    125\u001B[0m model \u001B[38;5;241m=\u001B[39m load_or_train_autoencoder(x_train, x_val, input_dim, encoding_dim, epochs, batch_size)\n\u001B[0;32m    127\u001B[0m \u001B[38;5;66;03m# Calculate optimized threshold using PSO\u001B[39;00m\n\u001B[1;32m--> 128\u001B[0m threshold \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_threshold\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormal_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;66;03m# Perform anomaly detection on test data\u001B[39;00m\n\u001B[0;32m    131\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m detect_anomalies(model, test_tensor, threshold)\n",
      "Cell \u001B[1;32mIn[2], line 89\u001B[0m, in \u001B[0;36mcalculate_threshold\u001B[1;34m(model, data)\u001B[0m\n\u001B[0;32m     86\u001B[0m         precision, recall, f1, _ \u001B[38;5;241m=\u001B[39m precision_recall_fscore_support(y_true, y_pred, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     87\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39mf1  \u001B[38;5;66;03m# 最大化 F1 分数\u001B[39;00m\n\u001B[1;32m---> 89\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m GlobalBestPSO(n_particles\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, dimensions\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, options\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mc1\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mc2\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.3\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.9\u001B[39m}, bounds\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[0;32m     90\u001B[0m best_cost, best_threshold \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39moptimize(pso_objective, iters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m)\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m best_threshold[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mamax\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\pt-gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2820\u001B[0m, in \u001B[0;36mamax\u001B[1;34m(a, axis, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m   2703\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_amax_dispatcher)\n\u001B[0;32m   2704\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mamax\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue, initial\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue,\n\u001B[0;32m   2705\u001B[0m          where\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue):\n\u001B[0;32m   2706\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2707\u001B[0m \u001B[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001B[39;00m\n\u001B[0;32m   2708\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2818\u001B[0m \u001B[38;5;124;03m    5\u001B[39;00m\n\u001B[0;32m   2819\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2820\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapreduction\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaximum\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2821\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\pt-gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84\u001B[0m, in \u001B[0;36m_wrapreduction\u001B[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001B[0m\n\u001B[0;32m     82\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m reduction(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n\u001B[0;32m     83\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 84\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m reduction(axis\u001B[38;5;241m=\u001B[39maxis, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ufunc\u001B[38;5;241m.\u001B[39mreduce(obj, axis, dtype, out, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n",
      "\u001B[1;31mTypeError\u001B[0m: max() received an invalid combination of arguments - got (axis=NoneType, out=NoneType, ), but expected one of:\n * ()\n * (Tensor other)\n * (int dim, bool keepdim = False)\n      didn't match because some of the keywords were incorrect: axis, out\n * (name dim, bool keepdim = False)\n      didn't match because some of the keywords were incorrect: axis, out\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8ed8f97f7d098e2c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
